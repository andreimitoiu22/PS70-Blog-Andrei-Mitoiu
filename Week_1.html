<!DOCTYPE html>
<html lang="en">

<title>PS70: Intro to Digital Fabrication </title>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.1/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="./style.css" rel="stylesheet">

<nav class="navbar navbar-expand-sm navbar-light bg-light">
  <div style="align-items: left; justify-content:left;" class="container-fluid">
    <h3 class="nav-title"> PS70: Intro to Digital Fabrication</h3>
    <div class="navbar-nav">
      <h4><a class="nav-link" href="./index.html">Home</a></h4>
      <h4><a class="nav-link" href="./about.html">About me</a></h4>
    </div>
  </div>
</nav>

<body>

  <style>
    body{
        background-image:url(./Images_Index/pexels-joão-jesus-925743.jpg);
    }
</style>


<xmp style="display:none;">


# FINAL PROJECT INITIAL IDEAS

#              

##  <span style="color:rgb(44, 44, 44) ;">Hand-Controlled Camera Slider</span>
<p>

In this project idea, I hope to combine the precision of a motorized camera slider with the artistic character of human camerawork to create a camera slider that is controlled by a hand. The movement of the hand should not only be able to control the position of the camera but also its rotation.
<p\>

  <div class="flex-center-full-size">
    ![Hand tracker]](./Images_week_1/s-l500.jpg)
  </div>
  

</p>


###   <span style="color:rgb(78, 78, 78) ;">How will it track the hand?</span>

There are a couple available options for hand tracking, yet the most accessible option seems to be through the use of [OpenCV’s AI hand tracking software](https://medium.com/analytics-vidhya/hand-detection-and-finger-counting-using-opencv-python-5b594704eb08) - which can be implemented in python. The AI program takes the live footage from a webcam and is able to track the hand relatively accurately. The co-ordinates can then be sent and used by the slider to move and rotate the camera accordingly.  
<div class="flex-center-full-size">
  ![Hand tracker]](./Images_week_1/1_mqo4Gy4DJyWmiYiBGewWnQ.png)

</div>



Latency will be a big downside of this code, hence why I considered a faster, more accurate hand tracking system which can be implemented with the [Ultraleap 3Di Stereo Hand Tracking Camera](https://www.robotshop.com/en/ultraleap-3di-stereo-hand-tracking-camera.html?gclid=Cj0KCQjwpeaYBhDXARIsAEzItbE8lSrjxBlkWlPLjyrkQH4SEMNEySUs_9yjrZqXhoaMnV8A2bLilY4aAsR7EALw_wcB), which while accurate - is very expensive.

<div class="flex-center-full-size">
  ![Hand tracker]](./Images_week_1/ultraleap-infrared-hand-tracking.jpg)
</div>


### <span style="color:rgb(78, 78, 78) ;">How will the slider move?</span>

Two motors placed on each side of the slider will move the camera platform from left to right and vice versa using a belt. On the camera platform, underneath the camera will be placed a 360 degrees motor that will be able to rotate the camera.

<div class="flex-center-full-size">
  ![Diagram]](./Images_week_1/IMG-0331.PNG)
</div>

###<span style="color:rgb(78, 78, 78) ;">What are some potential issues?</span>


The biggest problem with this idea is the required strength of the motors to pull and rotate the camera - which might mean more expensive motors will be required. To combat this issue, I am willing to use a lighter camera (e.g. a webcam or a smartphone), and remove the camera rotation feature of the slider (if the rotating motor is too heavy for the pulling motors).
<p\>

<p>
  
  ##Face - Tracking shotgun microphone

  In this project idea, I hope to achieve a product that is able to make audio recording more convenient by having the camera-attached shotgun microphone following the face in front of the camera. 
  
  
  
  
  ###<span style="color:rgb(78, 78, 78) ;">How will it track the face?</span>
  
  There are two ways in which the facial data can be captured: either through the live feed of the actual camera, or through a separate webcam placed on the camera. Because working with the live feed from the camera might interfere with its performance and will lead to less flexibility in the type of camera angles I can capture, I believe the best course of action is to use the live feed from an attached wide-angle webcam for facial tracking.
  Facial tracking softwares has improved over the last couple of years, so finding latency free libraries will hopefully be easier. For now, I am thinking of using [OpenCV’s Face Recognition for Python](https://docs.opencv.org/3.4/da/d60/tutorial_face_main.html).
  
  <div class="flex-center-full-size">
    ![Image]](./Images_week_1/maxresdefault.jpg)
  </div>

  ###<span style="color:rgb(78, 78, 78) ;">How will the microphone move?</span>

  I think that the microphone could move with the help of two motors, each designated for one of the two axes. Depending on the data received from the facial recognition software, the microphone will move accordingly. For initial tests, I might attach a laser to the microphone to ensure he points at the person’s mouth accurately.
  
  <div class="flex-center-full-size">
    ![Image]](./Images_week_1/Modified_shotgun.png)
  </div>
  
  ###<span style="color:rgb(185, 185, 185) ;">What are some potential issues?</span>
  
  <span style="color:rgb(255, 255, 255) ;">Because I hope this to be a hand-free robot, I might have to use non-cable alternatives (such as bluetooth and wi-fi transmission techniques) to transfer the coordinates of the facial data - which in turn might create latency issues.
    Furthermore, the motors attached to the microphone might be too loud and therefore ruin the audio recorded by the shotgun (further tests are needed) - but I will also try to attach a light microphone so the motors aren't strained.</span>
   
  
<p\>



<p>
  #<span style="color:rgb(255, 255, 255) ;"> OTHER FIRST WEEK EXPERIENCES</span>
  <span style="color:rgb(255, 255, 255) ;"> In the first week, the assignment was centered around creating a website using HTML and GitHub, and I was familliar with none. Fortunately, I was able to use a template, and with the limited knowledge I had about HTML, I was able to create this website.
  The design is definitely not its strength, but I know that it is more than enough for the kind of work I will have to display on it. Whenever in doubt, I used the [W3Schools](https://www.w3schools.com/) website for information and help related to my issues. In the end, I was able to complete my [Home](./index.html), [About](./about.html) and [Week 1](./Week_1.html) page.
Furthermore, I downloaded all the apps required like [Fusion 360](https://www.autodesk.com/products/fusion-360/overview?term=1-YEAR&tab=subscription) for 3D modeling.</span>



<p\>
</xmp>
</body>

<script src="./strapdown.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" ></script>

</html>